{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "\n",
    "* Memodelkan Topik pada Dataset Spam Tipe-3 dan Hasil StructuredBased\n",
    "* Pada Code ini hanya menggunakan model LSA yang mana merupakan pemodelan terbaik dari variasi skenario pengujian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works based on https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "\n",
    "import pandas as pd\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import Phrases\n",
    "import pyLDAvis\n",
    "from random import randint\n",
    "import ast\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coherence Score\n",
    "\n",
    "* Menghitung Coherence Score untuk Menentukan Jumlah Topik Terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=3, step=1):\n",
    "        \"\"\"\n",
    "        Compute c_v coherence for various number of topics\n",
    "    \n",
    "        Parameters:\n",
    "        ----------\n",
    "        dictionary : Gensim dictionary\n",
    "        corpus : Gensim corpus\n",
    "        texts : List of input texts\n",
    "        limit : Max num of topics\n",
    "    \n",
    "        Returns:\n",
    "        -------\n",
    "        model_list : List of  topic models\n",
    "        coherence_values : Coherence values corresponding to the  model with respective number of topics\n",
    "        \"\"\"\n",
    "        coherence_values = []\n",
    "        model_list = []\n",
    "        print(\"start\")\n",
    "        for num_topics in range(start, limit, step):\n",
    "            print(\"num topic:\")\n",
    "            model = LsiModel(corpus, num_topics=num_topics, id2word=dictionary, chunksize=2000)\n",
    "            print(num_topics)\n",
    "            model_list.append(model)\n",
    "            coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "            coherence_values.append(coherencemodel.get_coherence()) \n",
    "        return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n",
    "\n",
    "* Input : Data Hasil dari StructuredBased.ipynb\n",
    "* Output : Model Topik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main ():\n",
    "\n",
    "    '''\n",
    "    def tokenize(text):\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        tokens = word_tokenize(str(text))\n",
    "        return tokens\n",
    "    for i in range(len(data)):\n",
    "        clean.append(tokenize(data['clean'][i]))\n",
    "    ''' \n",
    "    #Data Hasil dari StructuredBased.ipynb\n",
    "    data = pd.read_csv('Data/Output/1. Preprocessing/amz_spam323_token_ag.csv', sep=',', encoding='latin-1')\n",
    "    clean=data['clean']\n",
    "    clean = list(map(ast.literal_eval,clean))\n",
    "    \n",
    "    #Membuat token bigram \n",
    "    bigram = Phrases(clean, min_count=10)\n",
    "    for idx in range(len(clean)):\n",
    "        for token in bigram[clean[idx]]:\n",
    "            if '_' in token:\n",
    "                clean[idx].append(token)\n",
    "    \n",
    "    #Membuat kamus kata\n",
    "    \n",
    "    dictionary = gensim.corpora.Dictionary(clean)\n",
    "    \n",
    "    #Preview\n",
    "    count = 0\n",
    "    for k, v in dictionary.iteritems():\n",
    "        print(k, v)\n",
    "        count += 1\n",
    "        if count > 5:\n",
    "            break\n",
    "    \n",
    "    dictionary.filter_extremes()\n",
    "    \n",
    "    #Membuat bag of word (kemunculan kata)\n",
    "    bow_corpus = [dictionary.doc2bow(doc) for doc in clean]\n",
    "    print(\"bow\")\n",
    "    print(\"coherence\")\n",
    "    print(\"done\")\n",
    "    model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=bow_corpus, texts=clean, start=3, limit=8, step=1)\n",
    "    \n",
    "    # Graf Model topik dan Coh_score\n",
    "    limit=8; start=3; step=1;\n",
    "    x = range(start, limit, step)\n",
    "    plt.plot(x, coherence_values)\n",
    "    plt.xlabel(\"Num Topics on BoW corpus\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"coherence_values\"))\n",
    "    plt.show()\n",
    "    \n",
    "    print(coherence_values)\n",
    "    lsimodel_model = model_list   \n",
    "    \n",
    "    return lsimodel_model, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model Topik Terbaik\n",
    "\n",
    "* berdasarkan Coherence Score Tertinggi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    lsimodel_model, coherence_values=main()\n",
    "    print(lsimodel_model)\n",
    "    print(coherence_values)\n",
    "    for idx, topic in lsimodel_model[2].print_topics(5): \n",
    "        print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "        \n",
    "    #lsimodel_model[4].save('Data/Output/2. Topic Modeling/lsimodelmodel_26_12_3 topik_best2') #array lsimodel_model disesuaikan dengan coh_score tertinggi\n",
    "    #model terbaik : lsimodelmodel_26_12_3 topik_best2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
