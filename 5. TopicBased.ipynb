{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perluasan Berbasis Topik\n",
    "\n",
    "* infering topik spam tipe-3 pada dataset spam tipe-1\n",
    "* menggunakan topic score (probability score topic) tertinggi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim.models import HdpModel \n",
    "from gensim.models.nmf import Nmf\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import Phrases\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from random import randint\n",
    "import ast\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model Topik\n",
    "\n",
    "* Dari TopicModeling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model = LsiModel.load('Data/Output/2. Topic Modeling/lsimodelmodel_26_12_3 topik_best2', mmap='r')\n",
    "print(lsi_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data \n",
    "\n",
    "* token dari spam tipe-1 dan TopicBasedResult\n",
    "* untuk infering topic dan mendapatkan topik score berupa probability score per topik spmam tipe-3 pada dataset spam tipe-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/Output/1. Preprocessing/amz_spam1_token_ag.csv', sep=',', encoding='latin-1')\n",
    "df = pd.read_csv('Data/Output/1. Preprocessing/amz_spam323_token_ag.csv', sep=',', encoding='latin-1')\n",
    "\n",
    "clean = data['clean'];\n",
    "clean = list(map(ast.literal_eval,clean))\n",
    "\n",
    "cleanb = df['clean'];\n",
    "cleanb = list(map(ast.literal_eval,cleanb))\n",
    "\n",
    "#https://markroxor.github.io/gensim/static/notebooks/lda_training_tips.html\n",
    "bigram = Phrases(cleanb, min_count=10)\n",
    "for idx in range(len(cleanb)):\n",
    "    for token in bigram[cleanb[idx]]:\n",
    "        if '_' in token:\n",
    "            cleanb[idx].append(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pembentukan Bag of Word \n",
    "\n",
    "* index kata dan kemunculan kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kamus berdasarkan data spam 23\n",
    "dictionary = gensim.corpora.Dictionary(cleanb)\n",
    "\n",
    "# Preview\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 5:\n",
    "        break\n",
    "\n",
    "dictionary.filter_extremes()\n",
    "\n",
    "#bow dari data spam 1 karna yang ingin diklasifikasi review dari spam 1 \n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Infering* Topic Pada Unseen Document\n",
    "\n",
    "* Unseen Doc : Spam Tipe-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat list probabilitas tertinggi topik untuk semua dokumen\n",
    "topic_list = []\n",
    "score_list = []\n",
    "\n",
    "for i in range(len(bow_corpus)):\n",
    "    sorted_probability = sorted(lsi_model[bow_corpus[i]], key = lambda x: x[1], reverse=True)\n",
    "    topic_list.append(sorted_probability[0][0])\n",
    "    score_list.append(sorted_probability[0][1])\n",
    "\n",
    "data['topic'] = topic_list\n",
    "data['score'] = score_list \n",
    "\n",
    "print(data.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* menyimpan data topik dan score topik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('Data/Output/2. Topic Modeling/clean-topic-12-26_lsi-best2_07.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, score in sorted(lsi_model[bow_corpus[64]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lsi_model.print_topic(index)))\n",
    "\n",
    "for i in range(len(bow_corpus)):  \n",
    "    top_topics = lsi_model[bow_corpus[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data II\n",
    "\n",
    "* untuk menyatukan data yang terseleksi dari thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data tambahan spam 1 \n",
    "data_raw = pd.read_csv('Data/train_spam1 - juli.csv', sep=',', encoding='latin-1')\n",
    "raw = data_raw['Body']\n",
    "\n",
    "#data spam 2 3 + data tambahan dari prep postag\n",
    "\n",
    "data_raw_s = pd.read_csv('Data/Output/1. Preprocessing/amz_end_prep_ag.csv', sep=',', encoding='latin-1')\n",
    "raw_s = data_raw_s['clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Threshold \n",
    "\n",
    "* threshold pada topic score untuk menyeleksi spam-tipe-1 yang memiliki kemiripan topik dengan spam tipe-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data spam 3 \n",
    "\n",
    "seq_sel=[]\n",
    "for i in range(len(raw_s)):\n",
    "    seq_sel.append(raw_s[i])\n",
    "\n",
    "clean = data['clean']\n",
    "score = data['score']\n",
    "\n",
    "j=0\n",
    "\n",
    "#data spam 3 ditambah data spam 1 yang terpilih berdasarkan score\n",
    "\n",
    "for i in range(len(score)):\n",
    "    if (score[i] > 0.7):\n",
    "        j+=1\n",
    "        seq_sel.append(raw[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpan Hasil Perluasan Berbasis Topik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simpan hasil inference spam 1 ke berdasarkan topic modeling ke dalam DataFrame\n",
    "        \n",
    "import re\n",
    "d=pd.DataFrame(seq_sel, columns=['r'])\n",
    "\n",
    "#eliminasi data dengan jumlah kata dalam data kurang dari 10 kata\n",
    "for i in range(len(d['r'])):\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s',d['r'][i])\n",
    "    text = d['r'][i].split()\n",
    "    if  len(text)<10:\n",
    "        print(text)\n",
    "        d.drop(i, inplace=True)\n",
    "    if i==11:\n",
    "        d.drop(i, inplace=True)\n",
    "    elif i==9:\n",
    "        d.drop(i, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* kedalam csv dan txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simpan ke dalam excel \n",
    "d.to_csv('Data/Output/2. Topic Modeling/spam_seq_sel_ag3_12-26_lsi-best2_07_with structure prep.csv', index=False)\n",
    "\n",
    "#simpan spam 3 dan tambahan dari spam 1 ke dlm txt\n",
    "with open('Data/Output/5. Sequence/spam_seq_sel_ag3_12-26_lsi-best2_07_with structure prep.txt', 'w') as f:\n",
    "    for item in d['r']:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
