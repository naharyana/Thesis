{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikasi\n",
    "\n",
    "* Klasifikasi Menggunakan Dataset Asli + Dataset Hasil Peembangkitan Kata Spam tipe-3\n",
    "* Meliputi Data Non Spam dan Data Spam Tipe-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi Persiapan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def text_preprocess(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persiapan Data\n",
    "\n",
    "* Baca Data\n",
    "* Menghapus null Line\n",
    "* Data yang digunakan : Data Asli Spam Tipe-3 + Data Hasil Pembangkitan kata + Data Non Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cleaned original spam text \n",
    "\n",
    "linessel = pd.read_csv('Data/train_data - juli - Asli.csv', sep=',', encoding='latin-1')\n",
    "lines_sel = linessel['Body']\n",
    "\n",
    "# load cleaned text generated \n",
    "in_filename_gen = 'Data/Output/7. Generated/gen_w2v_lstm.txt'\n",
    "doc_gen = load_doc(in_filename_gen)\n",
    "lines_gen = doc_gen.split('\\n')\n",
    "\n",
    "# Load Non Spam text\n",
    "in_filename_rev = 'Data/Output/8. Klasifikasi/notspam.txt'\n",
    "doc_rev = load_doc(in_filename_rev)\n",
    "lines_rev = doc_rev.split('\\n')\n",
    "\n",
    "for i in lines_sel:\n",
    "    if i==\"\":\n",
    "        lines_sel.remove(i)\n",
    "\n",
    "for i in lines_gen:\n",
    "    if i==\"\":\n",
    "        lines_gen.remove(i)\n",
    "        \n",
    "for i in lines_rev:\n",
    "    if i==\"\":\n",
    "        lines_rev.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ekstraksi Fitur\n",
    "\n",
    "* Menggunakan pembobotan TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizertfidf1 = TfidfVectorizer(ngram_range=(1, 2),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "\n",
    "corpus_sel=[text_preprocess(i) for i in lines_sel]\n",
    "corpus_gen=[text_preprocess(i) for i in lines_gen]\n",
    "corpus_rev=[text_preprocess(i) for i in lines_rev]\n",
    "\n",
    "A = vectorizertfidf1.fit_transform(corpus_sel)\n",
    "B = vectorizertfidf1.transform(corpus_gen)\n",
    "C = vectorizertfidf1.transform(corpus_rev)\n",
    "\n",
    "ngram_sel = pd.DataFrame(A.toarray())\n",
    "ngram_gen = pd.DataFrame(B.toarray())\n",
    "ngram_rev = pd.DataFrame(C.toarray())\n",
    "\n",
    "fitur_sel=ngram_sel.fillna(0)\n",
    "fitur_gen=ngram_gen.fillna(0)\n",
    "fitur_rev=ngram_rev.fillna(0)\n",
    "\n",
    "#fitur_sel.to_csv('Data/Output/5. Sequence/nfitur-sel.csv', index=False)\n",
    "#fitur_gen.to_csv('Data/Output/5. Sequence/nfitur-gen.csv', index=False)\n",
    "#fitur_rev.to_csv('Data/Output/5. Sequence/nfitur-rev.csv', index=False)\n",
    "\n",
    "#penggaubngan data fitur tf idf\n",
    "fitur=pd.DataFrame(A.toarray()) # tambahan\n",
    "fitur=fitur.append(ngram_rev, ignore_index = True) #review\n",
    "fitur=fitur.append(ngram_gen, ignore_index = True) # spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning Model Klasifikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#labeling\n",
    "y_l=[]\n",
    "y_l=[1 for i in range(109)] #label spam \n",
    "for i in range(326):\n",
    "    y_l.append(0) # label non spam\n",
    "for i in range(109): # label spam generation - kontribusi\n",
    "    y_l.append(1)\n",
    "\n",
    "y = pd.DataFrame(y_l, columns=['Label'])\n",
    "from sklearn import svm\n",
    "\n",
    "#Modeling\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "clf= svm.SVC(kernel='linear', C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=2, gamma='auto', max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "\n",
    "#Training dan Evaluasi\n",
    "scores= cross_validate(clf, fitur, y, cv=10, scoring=['f1', 'recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Hasil Evaluasi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "print (statistics.mean(scores['test_f1']))\n",
    "print(scores['test_f1'])\n",
    "print(max(scores['test_f1']))\n",
    "print(min(scores['test_f1']))\n",
    "\n",
    "print (statistics.mean(scores['test_recall']))\n",
    "print((scores['test_recall']))\n",
    "print(max(scores['test_recall']))\n",
    "print(min(scores['test_recall']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
